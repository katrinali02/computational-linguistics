
A5 Qualitative Notes


What sorts of semantics are these dense vectors picking up, and what are they missing?


What sorts of tasks might they be better or worse at?

How do considerations of the construction of particular datasets impact whether we can be successful at their corresponding task?

1. Embeddings
- It seems like the embedding similarity calculations are better at finding associations than they are at finding synonyms or near-synonyms. For example, the word most similar to "man" was "woman," which is obviously its opposite (according to conventional gender).
- However, some interesting associations were foundâ€“for example, 2 of the top 5 most similar words to "african-american" were "middle-class" and "working-class" whereas the similar words to "caucasian" were things like "slavic" and "turkic." This shows that African-americans may have been talked about in the context of their socioeconomic status more than caucasians.

2. Word similarity
- I'm not sure if I'm interpreting these results correctly...but I'm pretty sure that this program shows that the using the WordSim dataset to judge similarity is less accurate than using the SimLex dataset (compared to human judgments).

3. Sentence similarity
- For some reason, my sentence similarity program has a bug ("'str' object cannot be interpreted as an integer") when I run it on its own, but it passes the autogravder. So I'm not exactly sure how to get to STS-B scores. My guess would be that the weighted sum predictions are more accurate than the unweighted.

4. Analogies
- The score for answering the questions with the analogy method was .28 and the score for answering with parallelism was .34, which means that the parallelism formula is probably more accurate in capturing semantic relations. 